{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "exploration.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacobbarkow/w207-final-project-barkow-laface-meehan-skokowski/blob/main/exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR0M5K3OoxlJ"
      },
      "source": [
        "# This tells matplotlib not to try opening a new window for each plot.\n",
        "%matplotlib inline\n",
        "\n",
        "# General libraries.\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# SK-learn libraries for learning.\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# SK-learn libraries for evaluation.\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# SK-learn library for importing the newsgroup data.\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "# SK-learn libraries for feature extraction from text.\n",
        "from sklearn.feature_extraction.text import *\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import nltk\n",
        "\n",
        "np.random.seed(0)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_pWbJMSoxlX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "02af2db0-7e73-4b36-9d06-16bb0d707eb9"
      },
      "source": [
        "fake_raw = pd.read_csv('Fake.csv')\n",
        "fake_raw['label'] = 'fake'\n",
        "\n",
        "true_raw = pd.read_csv('True.csv')\n",
        "true_raw['label'] = 'true'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-555f11b0e5f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfake_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Fake.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfake_raw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'fake'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrue_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'True.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrue_raw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'true'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Fake.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CkbU_gsoxlg",
        "outputId": "382c948c-baf5-4bb6-d3a3-17130226cf34"
      },
      "source": [
        "# sizes of fake and true datasets are similar\n",
        "# not sure if we should only include some\n",
        "\n",
        "print(len(fake_raw), len(true_raw))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "23481 21417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRTa6u_3oxlj",
        "outputId": "89911e74-2019-4d88-f5a9-b6a52d857178"
      },
      "source": [
        "full_set = fake_raw.append(true_raw)\n",
        "print(len(full_set))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qaBrLS6oxlm"
      },
      "source": [
        "full_set = shuffle(full_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6OI6pO_oxlo"
      },
      "source": [
        "train_data = full_set[:35000]\n",
        "test_data = full_set[35000:44000]\n",
        "dev_data = full_set[44000:]\n",
        "\n",
        "train_text, train_title, train_subject, train_labels = train_data['text'], train_data['title'], train_data['subject'], train_data['label']\n",
        "test_text, test_title, test_subject, test_labels = test_data['text'], test_data['title'], test_data['subject'], test_data['label']\n",
        "dev_text, dev_title, dev_subject, dev_labels = dev_data['text'], dev_data['title'], dev_data['subject'], dev_data['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No3fLt7Ioxlu"
      },
      "source": [
        "## Testing Simple Models - Article Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rfhS6Qcoxl2",
        "outputId": "ff0f7b58-f90a-456b-a02b-294e80c8eb1b"
      },
      "source": [
        "cv_train = CountVectorizer()\n",
        "train_text_cv = cv_train.fit_transform(train_text)\n",
        "test_text_cv = cv_train.transform(test_text)\n",
        "\n",
        "print(np.shape(train_text_cv))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(35000, 109908)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5uc3jmjoxl5",
        "outputId": "4b000201-dc61-41cc-8995-0f02ab9f9384"
      },
      "source": [
        "# testing MNB - scoring and F1\n",
        "\n",
        "mnb = MultinomialNB()\n",
        "mnb.fit(train_text_cv, train_labels)\n",
        "print(mnb.score(test_text_cv, test_labels))\n",
        "\n",
        "test_predicted = mnb.predict(test_text_cv)\n",
        "print(metrics.f1_score(test_labels, test_predicted, average=\"weighted\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9561111111111111\n",
            "0.9561222784815994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HwtoU4DoxmA",
        "outputId": "4599ac02-b280-4805-b833-e20ce223dcdd"
      },
      "source": [
        "# testing logistic regression - scoring and F1\n",
        "\n",
        "logreg = LogisticRegression(solver=\"liblinear\", multi_class=\"auto\")\n",
        "logreg.fit(train_text_cv, train_labels)\n",
        "print(logreg.score(test_text_cv, test_labels))\n",
        "\n",
        "test_predicted = logreg.predict(test_text_cv)\n",
        "print(metrics.f1_score(test_labels, test_predicted, average=\"weighted\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9954444444444445\n",
            "0.9954446065891727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vpDYiR9oxmC",
        "outputId": "7ca4da41-8199-46a3-99c7-0c20771f0add"
      },
      "source": [
        "# what are the most impactful words\n",
        "\n",
        "words = cv_train.get_feature_names()\n",
        "sort_array = np.argsort(logreg.coef_[0])\n",
        "\n",
        "for i in range(1, 11):\n",
        "    print(words[sort_array[-i]], logreg.coef_[0][sort_array[-i]])\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "for i in range(1, 11):\n",
        "    print(words[sort_array[i]], logreg.coef_[0][sort_array[i]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "reuters 7.338512318833623\n",
            "washington 0.8629743127193463\n",
            "said 0.6452391953924397\n",
            "thursday 0.5813205711920263\n",
            "bit 0.5575759061988066\n",
            "wednesday 0.5420015904083523\n",
            "republican 0.49823569781835364\n",
            "london 0.4962741722213087\n",
            "nov 0.45878413846247895\n",
            "market 0.4556959269399991\n",
            "\n",
            "\n",
            "read -1.0822895191660005\n",
            "com -0.8633270158201595\n",
            "image -0.8283507778846004\n",
            "us -0.7843088077024256\n",
            "featured -0.7679771244470786\n",
            "just -0.7489551937639962\n",
            "pic -0.7233833383553663\n",
            "watch -0.6865570990968554\n",
            "hillary -0.663001758422078\n",
            "gop -0.6490196057874936\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZHVSeIPoxmF"
      },
      "source": [
        "## Testing Simple Models - Title"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekliA8ojoxmG",
        "outputId": "2921e87d-ef5a-4fb2-98da-152dd2bcaf77"
      },
      "source": [
        "cv_train_ti = CountVectorizer()\n",
        "train_text_cv_ti = cv_train_ti.fit_transform(train_title)\n",
        "test_text_cv_ti = cv_train_ti.transform(test_title)\n",
        "\n",
        "print(np.shape(train_text_cv_ti))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(35000, 19396)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17XUlWF1oxmI",
        "outputId": "4489d37a-f06c-42dc-d75f-b68513491241"
      },
      "source": [
        "logreg_ti = LogisticRegression(solver=\"liblinear\", multi_class=\"auto\")\n",
        "logreg_ti.fit(train_text_cv_ti, train_labels)\n",
        "print(logreg_ti.score(test_text_cv_ti, test_labels))\n",
        "\n",
        "test_predicted_ti = logreg_ti.predict(test_text_cv_ti)\n",
        "print(metrics.f1_score(test_labels, test_predicted_ti, average=\"weighted\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9642222222222222\n",
            "0.964236476700352\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slEHV_K_oxmO",
        "outputId": "dcda8d0a-27fa-4b50-cdc8-4c73f43bc3e1"
      },
      "source": [
        "# what are the most impactful words\n",
        "\n",
        "words_ti = cv_train_ti.get_feature_names()\n",
        "sort_array_ti = np.argsort(logreg_ti.coef_[0])\n",
        "\n",
        "for i in range(1, 11):\n",
        "    print(words_ti[sort_array_ti[-i]], logreg_ti.coef_[0][sort_array_ti[-i]])\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "for i in range(1, 11):\n",
        "    print(words_ti[sort_array_ti[i]], logreg_ti.coef_[0][sort_array_ti[i]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "factbox 3.7412698794712864\n",
            "says 2.394252343680438\n",
            "urges 2.1814005941256713\n",
            "britain 2.009552975341399\n",
            "exclusive 1.859107491076504\n",
            "reuters 1.79963428940857\n",
            "zimbabwe 1.7975690130034685\n",
            "talks 1.7922251955768105\n",
            "seek 1.7544050159810252\n",
            "myanmar 1.6999705984351985\n",
            "\n",
            "\n",
            "breaking -4.189631714266171\n",
            "gop -3.8160122784548824\n",
            "us -3.6443869525272645\n",
            "watch -3.360705254269749\n",
            "boiler -3.325122726909894\n",
            "hillary -3.1573989920598398\n",
            "just -3.146966871823763\n",
            "racist -3.0878399583326885\n",
            "bernie -2.851391104879254\n",
            "details -2.4687539359854536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8eFy10ToxmU"
      },
      "source": [
        "## Testing Simple Models - Subject Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXYHS2ctoxmV",
        "outputId": "c222ba0b-3be2-43f7-ca8b-7b0bb66fd2f9"
      },
      "source": [
        "cv_train_subj = CountVectorizer()\n",
        "train_text_cv_subj = cv_train_subj.fit_transform(train_subject)\n",
        "test_text_cv_subj = cv_train_subj.transform(test_subject)\n",
        "\n",
        "print(np.shape(train_text_cv_subj))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(35000, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtTdZjw9oxmW",
        "outputId": "c30f0555-095d-4dbc-a67a-dc384b3f3d2d"
      },
      "source": [
        "# testing MNB - scoring and F1\n",
        "\n",
        "mnb_subj = MultinomialNB()\n",
        "mnb_subj.fit(train_text_cv_subj, train_labels)\n",
        "print(mnb_subj.score(test_text_cv_subj, test_labels))\n",
        "\n",
        "test_predicted_subj = mnb_subj.predict(test_text_cv_subj)\n",
        "print(metrics.f1_score(test_labels, test_predicted_subj, average=\"weighted\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFIlnEZvoxmX",
        "outputId": "59bcd5f0-3311-4be3-f0a9-f0133c3d79e3"
      },
      "source": [
        "# testing logistic regression - scoring and F1\n",
        "\n",
        "logreg_subj = LogisticRegression(solver=\"liblinear\", multi_class=\"auto\")\n",
        "logreg_subj.fit(train_text_cv_subj, train_labels)\n",
        "print(logreg_subj.score(test_text_cv_subj, test_labels))\n",
        "\n",
        "test_predicted_subj = logreg_subj.predict(test_text_cv_subj)\n",
        "print(metrics.f1_score(test_labels, test_predicted_subj, average=\"weighted\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0xdYipeoxmY"
      },
      "source": [
        "### Subject field is actually useless because subjects can already uniquely identify if it's real or fake"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6lrMzqVoxmZ"
      },
      "source": [
        "## How successful is the model with just the word \"reuters\"?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BywhSTI-oxma",
        "outputId": "5338b4c9-88ab-4db3-8bae-64720e0bd421"
      },
      "source": [
        "cv_train_r = CountVectorizer(vocabulary=['reuters'])\n",
        "train_text_cv_r = cv_train_r.fit_transform(train_text)\n",
        "test_text_cv_r = cv_train_r.transform(test_text)\n",
        "\n",
        "print(np.shape(train_text_cv_r))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(35000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWERzE7Joxmb",
        "outputId": "953d0e16-24b2-4873-fce2-26c5d7682605"
      },
      "source": [
        "logreg_r = LogisticRegression(solver=\"liblinear\", multi_class=\"auto\")\n",
        "logreg_r.fit(train_text_cv_r, train_labels)\n",
        "print(logreg_r.score(test_text_cv_r, test_labels))\n",
        "\n",
        "test_predicted_r = logreg_r.predict(test_text_cv_r)\n",
        "print(metrics.f1_score(test_labels, test_predicted_r, average=\"weighted\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9917777777777778\n",
            "0.9917799006805953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0uNiuj6oxmj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}